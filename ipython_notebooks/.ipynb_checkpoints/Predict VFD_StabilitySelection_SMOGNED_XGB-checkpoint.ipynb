{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "name": "Predicting VFD in Features_topn_smogned",
    "hide_input": false,
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predicting VFD in Features_topn_smogned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notebook automatically generated from your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model XGBoost (All), trained on 2022-01-23 20:45:29."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generated on 2022-01-31 06:32:44.057160"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "prediction\nThis notebook will reproduce the steps for a REGRESSION on  Features_topn_smogned.\nThe main objective is to predict the variable VFD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Warning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The goal of this notebook is to provide an easily readable and explainable code that reproduces the main steps\nof training the model. It is not complete: some of the preprocessing done by the DSS visual machine learning is not\nreplicated in this notebook. This notebook will not give the same results and model performance as the DSS visual machine\nlearning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s start with importing the required libs :"
      ]
    },
    {
      "execution_count": 1,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\nimport dataiku\nimport numpy as np\nimport pandas as pd\nimport sklearn as sk\nimport dataiku.core.pandasutils as pdu\nfrom dataiku.doctor.preprocessing import PCA\nfrom collections import defaultdict, Counter"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And tune pandas display options:"
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pd.set_option(\u0027display.width\u0027, 3000)\npd.set_option(\u0027display.max_rows\u0027, 200)\npd.set_option(\u0027display.max_columns\u0027, 200)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Importing base data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first step is to get our machine learning dataset:"
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# We apply the preparation that you defined. You should not modify this.\npreparation_steps \u003d []\npreparation_output_schema \u003d {\u0027columns\u0027: [{\u0027name\u0027: \u0027StudyID_Int\u0027, \u0027type\u0027: \u0027bigint\u0027}, {\u0027name\u0027: \u0027Sex\u0027, \u0027type\u0027: \u0027string\u0027}, {\u0027name\u0027: \u0027Race\u0027, \u0027type\u0027: \u0027string\u0027}, {\u0027name\u0027: \u0027Infection Status\u0027, \u0027type\u0027: \u0027string\u0027}, {\u0027name\u0027: \u0027ECMO\u0027, \u0027type\u0027: \u0027boolean\u0027}, {\u0027name\u0027: \u0027PELOD\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027PRISM\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027Age_years\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027TNFSF8\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027TLR5\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027SYK\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027PRDM1\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027LTB4R\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027LILRA3\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IRF7\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IL6\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IL1RN\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IL1R2\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IL18RAP\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IL16\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027IKZF2\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027HAMP\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027FKBP5\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027FCGR3A/B\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027EGR1\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027DPP4\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027CXCR1\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027CSF2RB\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027CLEC4E\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027CFD\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027CD9\u0027, \u0027type\u0027: \u0027double\u0027}, {\u0027name\u0027: \u0027VFD\u0027, \u0027type\u0027: \u0027bigint\u0027}], \u0027userModified\u0027: False}\n\nml_dataset_handle \u003d dataiku.Dataset(\u0027Features_topn_smogned\u0027)\nml_dataset_handle.set_preparation_steps(preparation_steps, preparation_output_schema)\n%time ml_dataset \u003d ml_dataset_handle.get_dataframe(limit \u003d 100000)\n\nprint (\u0027Base data has %i rows and %i columns\u0027 % (ml_dataset.shape[0], ml_dataset.shape[1]))\n# Five first records\",\nml_dataset.head(5)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "CPU times: user 16.8 ms, sys: 6.83 ms, total: 23.6 ms\nWall time: 67.3 ms\nBase data has 37 rows and 32 columns\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "   StudyID_Int     Sex   Race Infection Status ECMO   PELOD     PRISM  Age_years    TNFSF8      TLR5       SYK     PRDM1     LTB4R    LILRA3      IRF7       IL6     IL1RN     IL1R2   IL18RAP      IL16     IKZF2      HAMP     FKBP5  FCGR3A/B      EGR1      DPP4     CXCR1    CSF2RB    CLEC4E       CFD       CD9  VFD\n0           23  Female  Black             None   No  0.1875  0.137931   0.025790  0.106840  0.438272  0.125786  0.384307  0.634956  0.172957  0.465784  0.003770  0.170401  0.643968  0.071853  0.217899  0.634783  0.211567  0.835682  0.537386  0.147477  0.685083  0.463647  0.518805  0.788187  0.484848  0.162456   27\n1           34  Female  White             None   No  0.5000  0.137931   0.102515  0.212052  0.518519  0.933962  0.756605  0.724558  0.637416  0.121348  0.064859  0.391848  0.125299  0.063749  1.000000  0.652174  0.349195  0.409240  0.483965  0.656907  0.132597  0.539333  0.284382  0.440839  0.260606  0.098717   25\n2           39    Male  Black               Co   No  0.4375  0.413793   0.100580  0.092508  0.172840  0.015723  0.450761  0.219027  0.350776  0.125698  0.031155  0.317199  0.025132  0.014587  0.111868  0.182609  0.493411  0.067661  0.246661  0.106216  0.055249  0.128725  0.225020  0.312547  0.296970  0.042363   25\n3           42  Female  Black            Viral   No  0.5000  0.586207   0.014829  0.000651  0.018519  0.006289  0.009608  0.008850  0.006946  0.000519  0.000998  0.004598  0.003590  0.001621  0.006809  0.008696  0.008785  0.004587  0.000709  0.004153  0.000000  0.002384  0.002311  0.003950  0.012121  0.000389   28\n4           44    Male  White               Co   No  0.5000  0.206897   0.001934  0.044951  0.419753  0.072327  0.748599  0.225664  0.296365  0.467667  0.025611  0.888655  0.062590  0.029173  0.159533  0.373913  0.235725  0.203145  0.976465  0.175802  0.132597  0.572408  1.000000  1.000000  0.218182  0.008162   23",
            "text/html": "\n            \u003cbutton style\u003d\"display:none\" \n            class\u003d\"btn btn-default ipython-export-btn\" \n            id\u003d\"btn-df-938e65f3-fa8c-4a67-913f-d4f0a9e2d0a9\" \n            onclick\u003d\"_export_df(\u0027938e65f3-fa8c-4a67-913f-d4f0a9e2d0a9\u0027)\"\u003e\n                Export dataframe\n            \u003c/button\u003e\n            \n            \u003cscript\u003e\n                \n                function _check_export_df_possible(dfid,yes_fn,no_fn) {\n                    console.log(\u0027Checking dataframe exportability...\u0027)\n                    if(!IPython || !IPython.notebook || !IPython.notebook.kernel || !IPython.notebook.kernel) {\n                        console.log(\u0027Export is not possible (IPython kernel is not available)\u0027)\n                        if(no_fn) {\n                            no_fn();\n                        }\n                    } else {\n                        var pythonCode \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._check_export_stdout(\"\u0027+dfid+\u0027\")\u0027;\n                        IPython.notebook.kernel.execute(pythonCode,{iopub: {output: function(resp) {\n                            console.info(\"Exportability response\", resp);\n                            var size \u003d /^([0-9]+)x([0-9]+)$/.exec(resp.content.data || resp.content.text)\n                            if(!size) {\n                                console.log(\u0027Export is not possible (dataframe is not in-memory anymore)\u0027)\n                                if(no_fn) {\n                                    no_fn();\n                                }\n                            } else {\n                                console.log(\u0027Export is possible\u0027)\n                                if(yes_fn) {\n                                    yes_fn(1*size[1],1*size[2]);\n                                }\n                            }\n                        }}});\n                    }\n                }\n            \n                function _export_df(dfid) {\n                    \n                    var btn \u003d $(\u0027#btn-df-\u0027+dfid);\n                    var btns \u003d $(\u0027.ipython-export-btn\u0027);\n                    \n                    _check_export_df_possible(dfid,function() {\n                        \n                        window.parent.openExportModalFromIPython(\u0027Pandas dataframe\u0027,function(data) {\n                            btns.prop(\u0027disabled\u0027,true);\n                            btn.text(\u0027Exporting...\u0027);\n                            var command \u003d \u0027from dataiku.notebook.export import IPythonExporter;IPythonExporter._run_export(\"\u0027+dfid+\u0027\",\"\u0027+data.exportId+\u0027\")\u0027;\n                            var callback \u003d {iopub:{output: function(resp) {\n                                console.info(\"CB resp:\", resp);\n                                _check_export_df_possible(dfid,function(rows, cols) {\n                                    $(\u0027#btn-df-\u0027+dfid)\n                                        .css(\u0027display\u0027,\u0027inline-block\u0027)\n                                        .text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027)\n                                        .prop(\u0027disabled\u0027,false);\n                                },function() {\n                                    $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027none\u0027);\n                                });\n                            }}};\n                            IPython.notebook.kernel.execute(command,callback,{silent:false}); // yes, silent now defaults to true. figures.\n                        });\n                    \n                    }, function(){\n                            alert(\u0027Unable to export : the Dataframe object is not loaded in memory\u0027);\n                            btn.css(\u0027display\u0027,\u0027none\u0027);\n                    });\n                    \n                }\n                \n                (function(dfid) {\n                \n                    var retryCount \u003d 10;\n                \n                    function is_valid_websock(s) {\n                        return s \u0026\u0026 s.readyState\u003d\u003d1;\n                    }\n                \n                    function check_conn() {\n                        \n                        if(!IPython || !IPython.notebook) {\n                            // Don\u0027t even try to go further\n                            return;\n                        }\n                        \n                        // Check if IPython is ready\n                        console.info(\"Checking conn ...\")\n                        if(IPython.notebook.kernel\n                        \u0026\u0026 IPython.notebook.kernel\n                        \u0026\u0026 is_valid_websock(IPython.notebook.kernel.ws)\n                        ) {\n                            \n                            _check_export_df_possible(dfid,function(rows, cols) {\n                                $(\u0027#btn-df-\u0027+dfid).css(\u0027display\u0027,\u0027inline-block\u0027);\n                                $(\u0027#btn-df-\u0027+dfid).text(\u0027Export this dataframe (\u0027+rows+\u0027 rows, \u0027+cols+\u0027 cols)\u0027);\n                            });\n                            \n                        } else {\n                            console.info(\"Conditions are not ok\", IPython.notebook.kernel);\n                            \n                            // Retry later\n                            \n                            if(retryCount\u003e0) {\n                                setTimeout(check_conn,500);\n                                retryCount--;\n                            }\n                            \n                        }\n                    };\n                    \n                    setTimeout(check_conn,100);\n                    \n                })(\"938e65f3-fa8c-4a67-913f-d4f0a9e2d0a9\");\n                \n            \u003c/script\u003e\n            \n        \u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003eStudyID_Int\u003c/th\u003e\n      \u003cth\u003eSex\u003c/th\u003e\n      \u003cth\u003eRace\u003c/th\u003e\n      \u003cth\u003eInfection Status\u003c/th\u003e\n      \u003cth\u003eECMO\u003c/th\u003e\n      \u003cth\u003ePELOD\u003c/th\u003e\n      \u003cth\u003ePRISM\u003c/th\u003e\n      \u003cth\u003eAge_years\u003c/th\u003e\n      \u003cth\u003eTNFSF8\u003c/th\u003e\n      \u003cth\u003eTLR5\u003c/th\u003e\n      \u003cth\u003eSYK\u003c/th\u003e\n      \u003cth\u003ePRDM1\u003c/th\u003e\n      \u003cth\u003eLTB4R\u003c/th\u003e\n      \u003cth\u003eLILRA3\u003c/th\u003e\n      \u003cth\u003eIRF7\u003c/th\u003e\n      \u003cth\u003eIL6\u003c/th\u003e\n      \u003cth\u003eIL1RN\u003c/th\u003e\n      \u003cth\u003eIL1R2\u003c/th\u003e\n      \u003cth\u003eIL18RAP\u003c/th\u003e\n      \u003cth\u003eIL16\u003c/th\u003e\n      \u003cth\u003eIKZF2\u003c/th\u003e\n      \u003cth\u003eHAMP\u003c/th\u003e\n      \u003cth\u003eFKBP5\u003c/th\u003e\n      \u003cth\u003eFCGR3A/B\u003c/th\u003e\n      \u003cth\u003eEGR1\u003c/th\u003e\n      \u003cth\u003eDPP4\u003c/th\u003e\n      \u003cth\u003eCXCR1\u003c/th\u003e\n      \u003cth\u003eCSF2RB\u003c/th\u003e\n      \u003cth\u003eCLEC4E\u003c/th\u003e\n      \u003cth\u003eCFD\u003c/th\u003e\n      \u003cth\u003eCD9\u003c/th\u003e\n      \u003cth\u003eVFD\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e23\u003c/td\u003e\n      \u003ctd\u003eFemale\u003c/td\u003e\n      \u003ctd\u003eBlack\u003c/td\u003e\n      \u003ctd\u003eNone\u003c/td\u003e\n      \u003ctd\u003eNo\u003c/td\u003e\n      \u003ctd\u003e0.1875\u003c/td\u003e\n      \u003ctd\u003e0.137931\u003c/td\u003e\n      \u003ctd\u003e0.025790\u003c/td\u003e\n      \u003ctd\u003e0.106840\u003c/td\u003e\n      \u003ctd\u003e0.438272\u003c/td\u003e\n      \u003ctd\u003e0.125786\u003c/td\u003e\n      \u003ctd\u003e0.384307\u003c/td\u003e\n      \u003ctd\u003e0.634956\u003c/td\u003e\n      \u003ctd\u003e0.172957\u003c/td\u003e\n      \u003ctd\u003e0.465784\u003c/td\u003e\n      \u003ctd\u003e0.003770\u003c/td\u003e\n      \u003ctd\u003e0.170401\u003c/td\u003e\n      \u003ctd\u003e0.643968\u003c/td\u003e\n      \u003ctd\u003e0.071853\u003c/td\u003e\n      \u003ctd\u003e0.217899\u003c/td\u003e\n      \u003ctd\u003e0.634783\u003c/td\u003e\n      \u003ctd\u003e0.211567\u003c/td\u003e\n      \u003ctd\u003e0.835682\u003c/td\u003e\n      \u003ctd\u003e0.537386\u003c/td\u003e\n      \u003ctd\u003e0.147477\u003c/td\u003e\n      \u003ctd\u003e0.685083\u003c/td\u003e\n      \u003ctd\u003e0.463647\u003c/td\u003e\n      \u003ctd\u003e0.518805\u003c/td\u003e\n      \u003ctd\u003e0.788187\u003c/td\u003e\n      \u003ctd\u003e0.484848\u003c/td\u003e\n      \u003ctd\u003e0.162456\u003c/td\u003e\n      \u003ctd\u003e27\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e34\u003c/td\u003e\n      \u003ctd\u003eFemale\u003c/td\u003e\n      \u003ctd\u003eWhite\u003c/td\u003e\n      \u003ctd\u003eNone\u003c/td\u003e\n      \u003ctd\u003eNo\u003c/td\u003e\n      \u003ctd\u003e0.5000\u003c/td\u003e\n      \u003ctd\u003e0.137931\u003c/td\u003e\n      \u003ctd\u003e0.102515\u003c/td\u003e\n      \u003ctd\u003e0.212052\u003c/td\u003e\n      \u003ctd\u003e0.518519\u003c/td\u003e\n      \u003ctd\u003e0.933962\u003c/td\u003e\n      \u003ctd\u003e0.756605\u003c/td\u003e\n      \u003ctd\u003e0.724558\u003c/td\u003e\n      \u003ctd\u003e0.637416\u003c/td\u003e\n      \u003ctd\u003e0.121348\u003c/td\u003e\n      \u003ctd\u003e0.064859\u003c/td\u003e\n      \u003ctd\u003e0.391848\u003c/td\u003e\n      \u003ctd\u003e0.125299\u003c/td\u003e\n      \u003ctd\u003e0.063749\u003c/td\u003e\n      \u003ctd\u003e1.000000\u003c/td\u003e\n      \u003ctd\u003e0.652174\u003c/td\u003e\n      \u003ctd\u003e0.349195\u003c/td\u003e\n      \u003ctd\u003e0.409240\u003c/td\u003e\n      \u003ctd\u003e0.483965\u003c/td\u003e\n      \u003ctd\u003e0.656907\u003c/td\u003e\n      \u003ctd\u003e0.132597\u003c/td\u003e\n      \u003ctd\u003e0.539333\u003c/td\u003e\n      \u003ctd\u003e0.284382\u003c/td\u003e\n      \u003ctd\u003e0.440839\u003c/td\u003e\n      \u003ctd\u003e0.260606\u003c/td\u003e\n      \u003ctd\u003e0.098717\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e39\u003c/td\u003e\n      \u003ctd\u003eMale\u003c/td\u003e\n      \u003ctd\u003eBlack\u003c/td\u003e\n      \u003ctd\u003eCo\u003c/td\u003e\n      \u003ctd\u003eNo\u003c/td\u003e\n      \u003ctd\u003e0.4375\u003c/td\u003e\n      \u003ctd\u003e0.413793\u003c/td\u003e\n      \u003ctd\u003e0.100580\u003c/td\u003e\n      \u003ctd\u003e0.092508\u003c/td\u003e\n      \u003ctd\u003e0.172840\u003c/td\u003e\n      \u003ctd\u003e0.015723\u003c/td\u003e\n      \u003ctd\u003e0.450761\u003c/td\u003e\n      \u003ctd\u003e0.219027\u003c/td\u003e\n      \u003ctd\u003e0.350776\u003c/td\u003e\n      \u003ctd\u003e0.125698\u003c/td\u003e\n      \u003ctd\u003e0.031155\u003c/td\u003e\n      \u003ctd\u003e0.317199\u003c/td\u003e\n      \u003ctd\u003e0.025132\u003c/td\u003e\n      \u003ctd\u003e0.014587\u003c/td\u003e\n      \u003ctd\u003e0.111868\u003c/td\u003e\n      \u003ctd\u003e0.182609\u003c/td\u003e\n      \u003ctd\u003e0.493411\u003c/td\u003e\n      \u003ctd\u003e0.067661\u003c/td\u003e\n      \u003ctd\u003e0.246661\u003c/td\u003e\n      \u003ctd\u003e0.106216\u003c/td\u003e\n      \u003ctd\u003e0.055249\u003c/td\u003e\n      \u003ctd\u003e0.128725\u003c/td\u003e\n      \u003ctd\u003e0.225020\u003c/td\u003e\n      \u003ctd\u003e0.312547\u003c/td\u003e\n      \u003ctd\u003e0.296970\u003c/td\u003e\n      \u003ctd\u003e0.042363\u003c/td\u003e\n      \u003ctd\u003e25\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e42\u003c/td\u003e\n      \u003ctd\u003eFemale\u003c/td\u003e\n      \u003ctd\u003eBlack\u003c/td\u003e\n      \u003ctd\u003eViral\u003c/td\u003e\n      \u003ctd\u003eNo\u003c/td\u003e\n      \u003ctd\u003e0.5000\u003c/td\u003e\n      \u003ctd\u003e0.586207\u003c/td\u003e\n      \u003ctd\u003e0.014829\u003c/td\u003e\n      \u003ctd\u003e0.000651\u003c/td\u003e\n      \u003ctd\u003e0.018519\u003c/td\u003e\n      \u003ctd\u003e0.006289\u003c/td\u003e\n      \u003ctd\u003e0.009608\u003c/td\u003e\n      \u003ctd\u003e0.008850\u003c/td\u003e\n      \u003ctd\u003e0.006946\u003c/td\u003e\n      \u003ctd\u003e0.000519\u003c/td\u003e\n      \u003ctd\u003e0.000998\u003c/td\u003e\n      \u003ctd\u003e0.004598\u003c/td\u003e\n      \u003ctd\u003e0.003590\u003c/td\u003e\n      \u003ctd\u003e0.001621\u003c/td\u003e\n      \u003ctd\u003e0.006809\u003c/td\u003e\n      \u003ctd\u003e0.008696\u003c/td\u003e\n      \u003ctd\u003e0.008785\u003c/td\u003e\n      \u003ctd\u003e0.004587\u003c/td\u003e\n      \u003ctd\u003e0.000709\u003c/td\u003e\n      \u003ctd\u003e0.004153\u003c/td\u003e\n      \u003ctd\u003e0.000000\u003c/td\u003e\n      \u003ctd\u003e0.002384\u003c/td\u003e\n      \u003ctd\u003e0.002311\u003c/td\u003e\n      \u003ctd\u003e0.003950\u003c/td\u003e\n      \u003ctd\u003e0.012121\u003c/td\u003e\n      \u003ctd\u003e0.000389\u003c/td\u003e\n      \u003ctd\u003e28\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e44\u003c/td\u003e\n      \u003ctd\u003eMale\u003c/td\u003e\n      \u003ctd\u003eWhite\u003c/td\u003e\n      \u003ctd\u003eCo\u003c/td\u003e\n      \u003ctd\u003eNo\u003c/td\u003e\n      \u003ctd\u003e0.5000\u003c/td\u003e\n      \u003ctd\u003e0.206897\u003c/td\u003e\n      \u003ctd\u003e0.001934\u003c/td\u003e\n      \u003ctd\u003e0.044951\u003c/td\u003e\n      \u003ctd\u003e0.419753\u003c/td\u003e\n      \u003ctd\u003e0.072327\u003c/td\u003e\n      \u003ctd\u003e0.748599\u003c/td\u003e\n      \u003ctd\u003e0.225664\u003c/td\u003e\n      \u003ctd\u003e0.296365\u003c/td\u003e\n      \u003ctd\u003e0.467667\u003c/td\u003e\n      \u003ctd\u003e0.025611\u003c/td\u003e\n      \u003ctd\u003e0.888655\u003c/td\u003e\n      \u003ctd\u003e0.062590\u003c/td\u003e\n      \u003ctd\u003e0.029173\u003c/td\u003e\n      \u003ctd\u003e0.159533\u003c/td\u003e\n      \u003ctd\u003e0.373913\u003c/td\u003e\n      \u003ctd\u003e0.235725\u003c/td\u003e\n      \u003ctd\u003e0.203145\u003c/td\u003e\n      \u003ctd\u003e0.976465\u003c/td\u003e\n      \u003ctd\u003e0.175802\u003c/td\u003e\n      \u003ctd\u003e0.132597\u003c/td\u003e\n      \u003ctd\u003e0.572408\u003c/td\u003e\n      \u003ctd\u003e1.000000\u003c/td\u003e\n      \u003ctd\u003e1.000000\u003c/td\u003e\n      \u003ctd\u003e0.218182\u003c/td\u003e\n      \u003ctd\u003e0.008162\u003c/td\u003e\n      \u003ctd\u003e23\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Initial data management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The preprocessing aims at making the dataset compatible with modeling.\nAt the end of this step, we will have a matrix of float numbers, with no missing values.\nWe\u0027ll use the features and the preprocessing steps defined in Models.\n\nLet\u0027s only keep selected features"
      ]
    },
    {
      "execution_count": 4,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_dataset \u003d ml_dataset[[\u0027CFD\u0027, \u0027IL1RN\u0027, \u0027Sex\u0027, \u0027CSF2RB\u0027, \u0027PELOD\u0027, \u0027PRDM1\u0027, \u0027IKZF2\u0027, \u0027LILRA3\u0027, \u0027LTB4R\u0027, \u0027DPP4\u0027, \u0027IL18RAP\u0027, \u0027CXCR1\u0027, \u0027Infection Status\u0027, \u0027VFD\u0027, \u0027Race\u0027, \u0027FCGR3A/B\u0027, \u0027ECMO\u0027, \u0027EGR1\u0027, \u0027SYK\u0027, \u0027IL1R2\u0027, \u0027IL16\u0027, \u0027PRISM\u0027, \u0027IL6\u0027, \u0027Age_years\u0027, \u0027IRF7\u0027, \u0027CD9\u0027, \u0027TNFSF8\u0027, \u0027TLR5\u0027, \u0027CLEC4E\u0027, \u0027HAMP\u0027, \u0027FKBP5\u0027]]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s first coerce categorical columns into unicode, numerical features into floats."
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# astype(\u0027unicode\u0027) does not work as expected\n\ndef coerce_to_unicode(x):\n    if sys.version_info \u003c (3, 0):\n        if isinstance(x, str):\n            return unicode(x,\u0027utf-8\u0027)\n        else:\n            return unicode(x)\n    else:\n        return str(x)\n\n\ncategorical_features \u003d [\u0027Sex\u0027, \u0027Infection Status\u0027, \u0027Race\u0027, \u0027ECMO\u0027]\nnumerical_features \u003d [\u0027CFD\u0027, \u0027IL1RN\u0027, \u0027CSF2RB\u0027, \u0027PELOD\u0027, \u0027PRDM1\u0027, \u0027IKZF2\u0027, \u0027LILRA3\u0027, \u0027LTB4R\u0027, \u0027DPP4\u0027, \u0027IL18RAP\u0027, \u0027CXCR1\u0027, \u0027FCGR3A/B\u0027, \u0027EGR1\u0027, \u0027SYK\u0027, \u0027IL1R2\u0027, \u0027IL16\u0027, \u0027PRISM\u0027, \u0027IL6\u0027, \u0027Age_years\u0027, \u0027IRF7\u0027, \u0027CD9\u0027, \u0027TNFSF8\u0027, \u0027TLR5\u0027, \u0027CLEC4E\u0027, \u0027HAMP\u0027, \u0027FKBP5\u0027]\ntext_features \u003d []\nfrom dataiku.doctor.utils import datetime_to_epoch\nfor feature in categorical_features:\n    ml_dataset[feature] \u003d ml_dataset[feature].apply(coerce_to_unicode)\nfor feature in text_features:\n    ml_dataset[feature] \u003d ml_dataset[feature].apply(coerce_to_unicode)\nfor feature in numerical_features:\n    if ml_dataset[feature].dtype \u003d\u003d np.dtype(\u0027M8[ns]\u0027) or (hasattr(ml_dataset[feature].dtype, \u0027base\u0027) and ml_dataset[feature].dtype.base \u003d\u003d np.dtype(\u0027M8[ns]\u0027)):\n        ml_dataset[feature] \u003d datetime_to_epoch(ml_dataset[feature])\n    else:\n        ml_dataset[feature] \u003d ml_dataset[feature].astype(\u0027double\u0027)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We renamed the target variable to a column named target"
      ]
    },
    {
      "execution_count": 6,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ml_dataset[\u0027__target__\u0027] \u003d ml_dataset[\u0027VFD\u0027]\ndel ml_dataset[\u0027VFD\u0027]\n\n\n# Remove rows for which the target is unknown.\nml_dataset \u003d ml_dataset[~ml_dataset[\u0027__target__\u0027].isnull()]"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cross-validation strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dataset needs to be split into 2 new sets, one that will be used for training the model (train set)\nand another that will be used to test its generalization capability (test set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a simple cross-validation strategy."
      ]
    },
    {
      "execution_count": 7,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train, test \u003d pdu.split_train_valid(ml_dataset, prop\u003d0.8)\nprint (\u0027Train data has %i rows and %i columns\u0027 % (train.shape[0], train.shape[1]))\nprint (\u0027Test data has %i rows and %i columns\u0027 % (test.shape[0], test.shape[1]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train data has 29 rows and 31 columns\nTest data has 8 rows and 31 columns\n",
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Features preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first thing to do at the features level is to handle the missing values.\nLet\u0027s reuse the settings defined in the model"
      ]
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "drop_rows_when_missing \u003d []\nimpute_when_missing \u003d [{\u0027feature\u0027: \u0027CFD\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IL1RN\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027CSF2RB\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027PELOD\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027PRDM1\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IKZF2\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027LILRA3\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027LTB4R\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027DPP4\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IL18RAP\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027CXCR1\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027FCGR3A/B\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027EGR1\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027SYK\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IL1R2\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IL16\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027PRISM\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IL6\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027Age_years\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027IRF7\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027CD9\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027TNFSF8\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027TLR5\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027CLEC4E\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027HAMP\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}, {\u0027feature\u0027: \u0027FKBP5\u0027, \u0027impute_with\u0027: \u0027MEAN\u0027}]\n\n# Features for which we drop rows with missing values\"\nfor feature in drop_rows_when_missing:\n    train \u003d train[train[feature].notnull()]\n    test \u003d test[test[feature].notnull()]\n    print (\u0027Dropped missing records in %s\u0027 % feature)\n\n# Features for which we impute missing values\"\nfor feature in impute_when_missing:\n    if feature[\u0027impute_with\u0027] \u003d\u003d \u0027MEAN\u0027:\n        v \u003d train[feature[\u0027feature\u0027]].mean()\n    elif feature[\u0027impute_with\u0027] \u003d\u003d \u0027MEDIAN\u0027:\n        v \u003d train[feature[\u0027feature\u0027]].median()\n    elif feature[\u0027impute_with\u0027] \u003d\u003d \u0027CREATE_CATEGORY\u0027:\n        v \u003d \u0027NULL_CATEGORY\u0027\n    elif feature[\u0027impute_with\u0027] \u003d\u003d \u0027MODE\u0027:\n        v \u003d train[feature[\u0027feature\u0027]].value_counts().index[0]\n    elif feature[\u0027impute_with\u0027] \u003d\u003d \u0027CONSTANT\u0027:\n        v \u003d feature[\u0027value\u0027]\n    train[feature[\u0027feature\u0027]] \u003d train[feature[\u0027feature\u0027]].fillna(v)\n    test[feature[\u0027feature\u0027]] \u003d test[feature[\u0027feature\u0027]].fillna(v)\n    print (\u0027Imputed missing values in feature %s with value %s\u0027 % (feature[\u0027feature\u0027], coerce_to_unicode(v)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "/Users/miladrad/Library/DataScienceStudio/kits/dataiku-dss-10.0.2-osx/python37.packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] \u003d value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Imputed missing values in feature CFD with value 0.30467563546342563\nImputed missing values in feature IL1RN with value 0.3532434813482188\nImputed missing values in feature CSF2RB with value 0.2897024003156147\nImputed missing values in feature PELOD with value 0.5646059008677387\nImputed missing values in feature PRDM1 with value 0.47137215836497165\nImputed missing values in feature IKZF2 with value 0.3480300308698054\nImputed missing values in feature LILRA3 with value 0.1670114894556121\nImputed missing values in feature LTB4R with value 0.28694098985491395\nImputed missing values in feature DPP4 with value 0.14130908378112714\nImputed missing values in feature IL18RAP with value 0.14619028367419967\nImputed missing values in feature CXCR1 with value 0.26996788296419444\nImputed missing values in feature FCGR3A/B with value 0.3614601326772245\nImputed missing values in feature EGR1 with value 0.1866439780297865\nImputed missing values in feature SYK with value 0.24750392765053972\nImputed missing values in feature IL1R2 with value 0.17540123544144823\nImputed missing values in feature IL16 with value 0.1703761445700083\nImputed missing values in feature PRISM with value 0.5458807337413707\nImputed missing values in feature IL6 with value 0.09072065815384871\nImputed missing values in feature Age_years with value 0.11678419034209038\nImputed missing values in feature IRF7 with value 0.27248430692493525\nImputed missing values in feature CD9 with value 0.13446700744874915\nImputed missing values in feature TNFSF8 with value 0.0655090976921468\nImputed missing values in feature TLR5 with value 0.2478600128336042\nImputed missing values in feature CLEC4E with value 0.32056669915494623\nImputed missing values in feature HAMP with value 0.13906872710009469\nImputed missing values in feature FKBP5 with value 0.228702106349619\n",
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now handle the categorical features (still using the settings defined in Models):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s dummy-encode the following features.\nA binary column is created for each of the 100 most frequent values."
      ]
    },
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "LIMIT_DUMMIES \u003d 100\n\ncategorical_to_dummy_encode \u003d [\u0027Sex\u0027, \u0027Infection Status\u0027, \u0027Race\u0027, \u0027ECMO\u0027]\n\n# Only keep the top 100 values\ndef select_dummy_values(train, features):\n    dummy_values \u003d {}\n    for feature in categorical_to_dummy_encode:\n        values \u003d [\n            value\n            for (value, _) in Counter(train[feature]).most_common(LIMIT_DUMMIES)\n        ]\n        dummy_values[feature] \u003d values\n    return dummy_values\n\nDUMMY_VALUES \u003d select_dummy_values(train, categorical_to_dummy_encode)\n\ndef dummy_encode_dataframe(df):\n    for (feature, dummy_values) in DUMMY_VALUES.items():\n        for dummy_value in dummy_values:\n            dummy_name \u003d u\u0027%s_value_%s\u0027 % (feature, coerce_to_unicode(dummy_value))\n            df[dummy_name] \u003d (df[feature] \u003d\u003d dummy_value).astype(float)\n        del df[feature]\n        print (\u0027Dummy-encoded feature %s\u0027 % feature)\n\ndummy_encode_dataframe(train)\n\ndummy_encode_dataframe(test)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Dummy-encoded feature Sex\nDummy-encoded feature Infection Status\nDummy-encoded feature Race\nDummy-encoded feature ECMO\nDummy-encoded feature Sex\nDummy-encoded feature Infection Status\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/Users/miladrad/Library/DataScienceStudio/kits/dataiku-dss-10.0.2-osx/python37.packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] \u003d value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Dummy-encoded feature Race\nDummy-encoded feature ECMO\n",
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u0027s rescale numerical features"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "rescale_features \u003d {\u0027CFD\u0027: \u0027AVGSTD\u0027, \u0027IL1RN\u0027: \u0027AVGSTD\u0027, \u0027CSF2RB\u0027: \u0027AVGSTD\u0027, \u0027PELOD\u0027: \u0027AVGSTD\u0027, \u0027PRDM1\u0027: \u0027AVGSTD\u0027, \u0027IKZF2\u0027: \u0027AVGSTD\u0027, \u0027LILRA3\u0027: \u0027AVGSTD\u0027, \u0027LTB4R\u0027: \u0027AVGSTD\u0027, \u0027DPP4\u0027: \u0027AVGSTD\u0027, \u0027IL18RAP\u0027: \u0027AVGSTD\u0027, \u0027CXCR1\u0027: \u0027AVGSTD\u0027, \u0027FCGR3A/B\u0027: \u0027AVGSTD\u0027, \u0027EGR1\u0027: \u0027AVGSTD\u0027, \u0027SYK\u0027: \u0027AVGSTD\u0027, \u0027IL1R2\u0027: \u0027AVGSTD\u0027, \u0027IL16\u0027: \u0027AVGSTD\u0027, \u0027PRISM\u0027: \u0027AVGSTD\u0027, \u0027IL6\u0027: \u0027AVGSTD\u0027, \u0027Age_years\u0027: \u0027AVGSTD\u0027, \u0027IRF7\u0027: \u0027AVGSTD\u0027, \u0027CD9\u0027: \u0027AVGSTD\u0027, \u0027TNFSF8\u0027: \u0027AVGSTD\u0027, \u0027TLR5\u0027: \u0027AVGSTD\u0027, \u0027CLEC4E\u0027: \u0027AVGSTD\u0027, \u0027HAMP\u0027: \u0027AVGSTD\u0027, \u0027FKBP5\u0027: \u0027AVGSTD\u0027}\nfor (feature_name, rescale_method) in rescale_features.items():\n    if rescale_method \u003d\u003d \u0027MINMAX\u0027:\n        _min \u003d train[feature_name].min()\n        _max \u003d train[feature_name].max()\n        scale \u003d _max - _min\n        shift \u003d _min\n    else:\n        shift \u003d train[feature_name].mean()\n        scale \u003d train[feature_name].std()\n    if scale \u003d\u003d 0.:\n        del train[feature_name]\n        del test[feature_name]\n        print (\u0027Feature %s was dropped because it has no variance\u0027 % feature_name)\n    else:\n        print (\u0027Rescaled %s\u0027 % feature_name)\n        train[feature_name] \u003d (train[feature_name] - shift).astype(np.float64) / scale\n        test[feature_name] \u003d (test[feature_name] - shift).astype(np.float64) / scale"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before actually creating our model, we need to split the datasets into their features and labels parts:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train \u003d train.drop(\u0027__target__\u0027, axis\u003d1)\nX_test \u003d test.drop(\u0027__target__\u0027, axis\u003d1)\n\ny_train \u003d np.array(train[\u0027__target__\u0027])\ny_test \u003d np.array(test[\u0027__target__\u0027])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can finally create our model!"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import xgboost as xgb\nclf \u003d xgb.XGBRegressor(\n                    max_depth\u003d3,\n                    learning_rate\u003d0.2,\n                    gamma\u003d0.0,\n                    min_child_weight\u003d1.0,\n                    max_delta_step\u003d0.0,\n                    subsample\u003d1.0,\n                    colsample_bytree\u003d1.0,\n                    colsample_bylevel\u003d1.0,\n                    reg_alpha\u003d0.0,\n                    reg_lambda\u003d1.0,\n                    n_estimators\u003d19,\n                    silent\u003d0,\n                    nthread\u003d4,\n                    scale_pos_weight\u003d1.0,\n                    base_score\u003d0.5,\n                    seed\u003d1337,\n                    missing\u003dNone,\n                  )"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... And train the model"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%time clf.fit(X_train, y_train)"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Build up our result dataset"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%time _predictions \u003d clf.predict(X_test)\npredictions \u003d pd.Series(data\u003d_predictions, index\u003dX_test.index, name\u003d\u0027predicted_value\u0027)\n\n# Build scored dataset\nresults_test \u003d X_test.join(predictions, how\u003d\u0027left\u0027)\nresults_test \u003d results_test.join(test[\u0027__target__\u0027], how\u003d\u0027left\u0027)\nresults_test \u003d results_test.rename(columns\u003d {\u0027__target__\u0027: \u0027VFD\u0027})"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can measure the model\u0027s accuracy:"
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "c \u003d  results_test[[\u0027predicted_value\u0027, \u0027VFD\u0027]].corr()\nprint (\u0027Pearson correlation: %s\u0027 % c[\u0027predicted_value\u0027][1])"
      ],
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That\u0027s it. It\u0027s now up to you to tune your preprocessing, your algo, and your analysis !\n"
      ]
    }
  ]
}